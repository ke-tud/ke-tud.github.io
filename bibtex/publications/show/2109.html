<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Preference-Based Policy Iteration: Leveraging Preference Learning for Reinforcement Learning - Knowledge Engineering Publications - Aigaion 2.0</title>
    <link href="../../aigaionengine/themes/default/css/positioning.css" rel="stylesheet" type="text/css" media="screen,projection,tv" />
    <link href="../../aigaionengine/themes/default/css/styling.css"     rel="stylesheet" type="text/css" media="screen,projection,tv" />
    <link href="../../aigaionengine/themes/kedesign/css/positioning.css" rel="stylesheet" type="text/css" media="screen,projection,tv" />
    <link href="../../aigaionengine/themes/kedesign/css/styling.css"     rel="stylesheet" type="text/css" media="screen,projection,tv" />
  </head>
  <body>
    <script type="text/javascript" src="../../aigaionengine/javascript/tree.js"></script>
    <script type="text/javascript" src="../../aigaionengine/javascript/prototype.js"></script>
    <script type="text/javascript" src="../../aigaionengine/javascript/scriptaculous.js"></script>
    <script type="text/javascript" src="../../aigaionengine/javascript/builder.js"></script>
    <script type="text/javascript" src="../../aigaionengine/javascript/externallinks.js"></script>
    <script type="text/javascript">
      //<![CDATA[
      base_url = 'http://www.ke.tu-darmstadt.de/bibtex/index.php/';
      //]]>
    </script>

    <div id="main_holder">
      <!-- Aigaion header: Logo, simple search form -->
      <div id="header_holder">
        <div id='quicksearch'>
          <form action="http://www.ke.tu-darmstadt.de/bibtex/search/quicksearch" method="post" accept-charset="utf-8">
<div>

<input type="hidden" name="formname" value="simplesearch" />
<input type="text" name="searchstring" value="" size="25"  /><input type="submit" name="submit_search" value="Search"  /></div>
</form>        </div>
                &nbsp;<a href='../../../index.html'><img border=0 src='../../aigaionengine/themes/kedesign/img/ke_logo.png' style='padding-left:20px; padding-top:8px'/></a>        
      </div>
      <!-- End of header -->

      <!-- Aigaion menu -->
<div id="menu_holder">
  <ul class="mainmenu">
    <li class="mainmenu-header">BROWSE</li>
    <li><ul class="mainmenu">
            <li class="mainmenu"><a href="../../authors/show/711.html">Topics</a></li>
    <li class="mainmenu"><a href="../../publications.html">All Publications</a></li>
        <li class="mainmenu"><a href="../showlist/type.html">All Journal Articles</a></li>
    <li class="mainmenu"><a href="../showlist/type.html#Book">All Books</a></li>
    <li class="mainmenu"><a href="../showlist/type.html#Incollection">All Book Chapters</a></li>
    <li class="mainmenu"><a href="../showlist/type.html#Proceedings">All Proceedings</a></li>
    <li class="mainmenu"><a href="../showlist/type.html#Inproceedings">All Articles in Proceedings</a></li>
    <li class="mainmenu"><a href="../../topics/single/77.html">All Technical Reports</a></li>
    <li class="mainmenu"><a href="http://www.ke.tu-darmstadt.de/bibtex/topics/single/33">All Student Theses</a></li>
    <? } ?>
        <li class="mainmenu"><a href="../showlist/recent.html">Recent</a></li>
    <li class="mainmenu"><a href="../../search.html">Search</a></li>

    </ul></li>
    <li class="mainmenu-spacer"></li>
    <li class="mainmenu-header">EXPORT</li>
    <li><ul class="mainmenu">
    <li class="mainmenu"><a href="../../export.html">Export all publications</a></li>
        </ul></li>

                </ul></li>
      </ul>
<br/><br/>
</div>
<!-- End of menu -->
      <!-- Aigaion main content -->
      <div id="content_holder">
      
      
      <!-- I think that here we want to have the (error) messages: -->
              <!---->
<div class='publication'>
  <div class='optionbox'>&nbsp;[<a href="../../export/publication/2109/bibtex.html" target="aigaion_export">BibTeX</a>]&nbsp;[<a href="../../export/publication/2109/ris.html" target="aigaion_export">RIS</a>]  </div>
  <div class='header'>Preference-Based Policy Iteration: Leveraging Preference Learning for Reinforcement Learning  </div>
  <table class='publication_details' width='100%'>
    <tr>
      <td>Type of publication:</td>
      <td>Inproceedings</td>
    </tr>
    <tr>
      <td>Citation:</td>
      <td>jf:ECML-PKDD-11</td>
    </tr>
    <tr>
      <td valign='top'>Booktitle:</td>
      <td valign='top'>Proceedings of the 22nd European Conference on Machine Learning and 	Principles and Practice of Knowledge Discovery in Databases (ECML 	PKDD 2011, Athens, Greece), Part I</td>
    </tr>
    <tr>
      <td valign='top'>Year:</td>
      <td valign='top'>2011</td>
    </tr>
    <tr>
      <td valign='top'>Pages:</td>
      <td valign='top'>312--327</td>
    </tr>
    <tr>
      <td valign='top'>Publisher:</td>
      <td valign='top'>Springer</td>
    </tr>
    <tr>
      <td valign='top'>URL:</td>
      <td valign='top'><a title='http://www.ke.informatik.tu-darmstadt.de/publications/papers/ECML-PKDD-11.pdf' href='http://www.ke.informatik.tu-darmstadt.de/publications/papers/ECML-PKDD-11.pdf' class='open_extern'>http://www.ke.informatik.tu-darmstadt.de/publications/papers/ECML-PKDD-11.pdf</a>
</td>
    </tr>
    <tr>
      <td valign='top'>Abstract:</td>
      <td valign='top'>This paper makes a first step toward the integration of two subfields of
machine learning, namely preference learning and reinforcement learning
(RL). An important motivation for a "preference-based" approach to
reinforcement learning is a possible extension of the type of feedback
an agent may learn from. In particular, while conventional RL methods
are essentially confined to deal with numerical rewards, there are many
applications in which this type of information is not naturally
available, and in which only qualitative reward signals are provided
instead. Therefore, building on novel methods for preference learning,
our general goal is to equip the RL agent with qualitative policy
models, such as ranking functions that allow for sorting its available
actions from most to least promising, as well as algorithms for learning
such models from qualitative feedback. Concretely, in this paper, we
build on an existing method for approximate policy iteration based on
roll-outs. While this approach is based on the use of classification
methods for generalization and policy learning, we make use of a
specific type of preference learning method called label ranking.
Advantages of our preference-based policy iteration method are
illustrated by means of two case studies.</td>
    </tr>
    <tr>
      <td valign='top'>Keywords:</td>
      <td valign='top'></td>
    </tr>
    <tr>
      <td valign='top'>Authors</td>
      <td valign='top'>
        <span class='authorlist'>
<a href="../../authors/show/3263.html" title="All information on Cheng, Weiwei">Cheng, Weiwei</a><br />
<a href="http://www.ke.tu-darmstadt.de/bibtex/authors/show/3259" title="All information on Furnkranz, Johannes">Fürnkranz, Johannes</a><br />
<a href="../../authors/show/3264.html" title="All information on Hullermeier, Eyke">Hüllermeier, Eyke</a><br />
<a href="http://www.ke.tu-darmstadt.de/bibtex/authors/show/708" title="All information on Park, Sang-Hyeun">Park, Sang-Hyeun</a><br />
        </span>
      </td>
    </tr>
    <tr>
      <td valign='top'>Editors</td>
      <td valign='top'>
        <span class='authorlist'>
<a href="../../authors/show/457.html" title="All information on Gunopulos, Dimitrios">Gunopulos, Dimitrios</a><br />
<a href="../../authors/show/2151.html" title="All information on Hofmann, Thomas">Hofmann, Thomas</a><br />
<a href="../../authors/show/1216.html" title="All information on Malerba, Donato">Malerba, Donato</a><br />
<a href="../../authors/show/2725.html" title="All information on Vazirgiannis, Michalis">Vazirgiannis, Michalis</a><br />
        </span>
      </td>
    </tr>
    <tr>
      <td colspan='2' valign='top'>
        <div class='optionbox'>
        </div>
        <div class='header'>Topics</div>
      </td>
    </tr>
    <tr>
      <td colspan='2' valign='top'>
<div id='topictree-holder'>
<ul class='topictree-list'>
<!-- topic browse displays -->
<li class='topictree-node'><img id      = 'min_topic_31' 
                   onclick = 'collapse("31","");' 
                   class   = 'icon'
                   src     = '../../aigaionengine/themes/kedesign/icons/tree_min.gif'
                   alt     = 'collapse'/>
<img id      = 'plus_topic_31' 
                   onclick = 'expand("31","");' 
                   class   = 'icon'
                   src     = '../../aigaionengine/themes/kedesign/icons/tree_plus.gif'
                   alt     = 'expand'/>
<script type='text/javascript'>Element.hide('plus_topic_31');</script><a href="../../../publications/index.html">Publications List</a> <span title='read: 0 of 499 publications'><i> 0/499</i></span>
</li>
<li class='topictree-children'>
<div id='topic_children_31' class='topictree-children'>
<ul class='topictree-list'>
<li class='topictree-leaf'><img  class   = 'icon'
                    src     = '../../aigaionengine/themes/kedesign/icons/tree_blank.gif'
                    alt     = 'blank'/>
<a href="../../topics/single/32.html">KE Group</a> <span title='read: 0 of 469 publications'><i> 0/469</i></span>
</li>
</ul>
</div>
</li>

<!-- End of topic browse displays -->
</ul>
</div>
      </td>
    </tr>
  </table>
</div>
      <div style='clear:both;'></div>
      </div>
      <!-- End of content_holder -->

    	<div id="footer_holder">
    		processing time: 0.0292 seconds.
    	</div>

    </div>
    <!-- End of main_holder -->
    
  </body>
</html>