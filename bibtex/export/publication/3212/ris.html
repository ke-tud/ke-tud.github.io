<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  </head>        
  <body>
    <pre>
TY  - CONF
ID  - fuernkranz20decodeml
T1  - Learning Structured Declarative Rule Sets — A Challenge for Deep Discrete Learning
A1  - Fürnkranz, Johannes
A1  - Hüllermeier, Eyke
A1  - Loza Mencía, Eneldo
A1  - Rapp, Michael
TI  - 2nd Workshop on Deep Continuous-Discrete Machine Learning (DeCoDeML)
Y1  - 2020
UR  - https://sites.google.com/view/decodeml-workshop-2020/program
N2  - Arguably the key reason for the success of deep neural networks is their ability to autonomously form non-linear combinations of the input features, which can be used in subsequent layers of the network. The analogon to this capability in inductive rule learning is to learn a structured rule base, where the inputs are combined to learn new auxiliary concepts, which can then be used as inputs by subsequent rules. Yet, research on rule learning algorithms that have such capabilities is still in their infancy, which is - we would argue - one of the key impediments to substantial progress in this field. In this position paper, we want to draw attention to this unsolved problem, with a particular focus on previous work in predicate invention and multi-label rule learning
ER  -
    </pre>
  </body>
</html>
